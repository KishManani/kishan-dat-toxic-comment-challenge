{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing import text, sequence\n",
    "from keras.layers import (Input, Embedding, GlobalAveragePooling1D, GlobalMaxPooling1D, Dense, \n",
    "                          SpatialDropout1D, Bidirectional, LSTM, concatenate)\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sys.path.insert(1, '..')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions and constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TARGETS = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def multi_roc_auc(y_true, y_score, verbose=False):\n",
    "    ''' Compute roc auc for each target and then average them\n",
    "    y_true - dataframe of true targets\n",
    "    y_score - dataframe of predicted target\n",
    "    '''\n",
    "    roc_scores = dict()\n",
    "    for target in TARGETS:\n",
    "        roc_score = roc_auc_score(y_true=y_true[target], y_score=y_score[target])\n",
    "        roc_scores[target] = roc_score\n",
    "\n",
    "    mean_roc_score = np.mean(list(roc_scores.values()))\n",
    "    \n",
    "    if verbose: \n",
    "        print('Mean ROC AUC overall all targets: {}'.format(mean_roc_score))\n",
    "    \n",
    "    return mean_roc_score, roc_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_dir = '../data/external/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(data_dir + 'train.csv')\n",
    "test_df = pd.read_csv(data_dir + 'test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = train_df.comment_text\n",
    "y_train = train_df.loc[:, TARGETS]\n",
    "\n",
    "X_test = test_df.comment_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab_size = 100000\n",
    "max_sequence_len = 200\n",
    "embedding_dim = 100\n",
    "glove_file = '../glove.6B/glove.6B.100d.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tk = text.Tokenizer(num_words=vocab_size, lower=True)\n",
    "tk.fit_on_texts(list(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Rectify issue with num_words in Keras\n",
    "# See issue: https://github.com/keras-team/keras/issues/8583#issuecomment-346981336\n",
    "tk.word_index = {e:i for e,i in tk.word_index.items() if i <= vocab_size} # <= because tokenizer is 1 indexed\n",
    "tk.word_index[tk.oov_token] = vocab_size + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_processed = tk.texts_to_sequences(X_train)\n",
    "X_test_processed = tk.texts_to_sequences(X_test)\n",
    "\n",
    "X_train_processed = sequence.pad_sequences(X_train_processed, maxlen=max_sequence_len)\n",
    "X_test_processed = sequence.pad_sequences(X_test_processed, maxlen=max_sequence_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load embeddings into dictionary\n",
    "embeddings_dict = {}\n",
    "with open(glove_file) as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        vector = np.asarray(values[1:], dtype='float32')\n",
    "        embeddings_dict[word] = vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_index = tk.word_index\n",
    "\n",
    "embedding_matrix = np.zeros((vocab_size+1, embedding_dim))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_dict.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i, :] = embedding_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build and train bidirectional LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_seq = Input(shape=(max_sequence_len,), dtype='int32')\n",
    "x = Embedding(input_dim=vocab_size+1,\n",
    "              output_dim=embedding_dim,\n",
    "              weights=[embedding_matrix],\n",
    "              input_length=max_sequence_len,\n",
    "              trainable=False)(input_seq)\n",
    "\n",
    "x = SpatialDropout1D(0.3)(x)\n",
    "x = Bidirectional(LSTM(128, return_sequences=True, dropout=0.1))(x)\n",
    "\n",
    "max_pool = GlobalMaxPooling1D()(x)\n",
    "avg_pool = GlobalAveragePooling1D()(x)\n",
    "x = concatenate([max_pool, avg_pool])\n",
    "\n",
    "output = Dense(6, activation='sigmoid')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_15 (InputLayer)           (None, 200)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_18 (Embedding)        (None, 200, 100)     10000100    input_15[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_7 (SpatialDro (None, 200, 100)     0           embedding_18[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_5 (Bidirectional) (None, 200, 256)     234496      spatial_dropout1d_7[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_4 (GlobalM (None, 256)          0           bidirectional_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_5 (Glo (None, 256)          0           bidirectional_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 512)          0           global_max_pooling1d_4[0][0]     \n",
      "                                                                 global_average_pooling1d_5[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 6)            3078        concatenate_3[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 10,237,674\n",
      "Trainable params: 237,574\n",
      "Non-trainable params: 10,000,100\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Model(input_seq, output)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "100/100 [==============================] - 3s 25ms/step - loss: 0.1866 - acc: 0.9450\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a6c1929b0>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(X_train_processed[:100], y_train.values[:100], batch_size=32, epochs=1, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Score on train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds_train = model.predict(X_train_processed[:10])\n",
    "preds_test = model.predict(X_test_processed[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_roc_score, roc_scores = multi_roc_auc(y_score=preds_train, y_true=y_train.values[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Output predictions for submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output_df = pd.concat([test_df['id'], preds_test_df], axis=1)\n",
    "output_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output_df.to_csv('../data/processed/lstm_glove_submission.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py36",
   "language": "python",
   "name": "py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
